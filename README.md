# üîç Debug AI - Generic Data Observability Engine
**Autor: Omer Arbel**

**CLIENT-AGNOSTIC** data lineage and debugging tool. Works with ANY database schema!

## üéØ What Does It Do?

Answers questions like:
- **"Why is this value calculated this way?"** ‚Üí Shows exact SQL logic
- **"What tables feed into this report?"** ‚Üí Shows full lineage tree
- **"Why is my result empty?"** ‚Üí Checks source table health

## ‚ú® Key Features

- ‚úÖ **100% Generic** - No hardcoded table names, schemas, or paths
- ‚úÖ **Auto-Detection** - Finds your database and SQL files automatically
- ‚úÖ **Secure** - SQL injection prevention, safe connection handling
- ‚úÖ **Extensible** - Easy to add new database types (Snowflake, Databricks)
- ‚úÖ **MCP Ready** - AI agents can connect via MCP protocol

---

## üìÅ Project Structure

```
debug_ai/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ db_config.py      ‚Üê Auto-detects paths, customizable via env vars
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ build_metadata.py ‚Üê Parses SQL files, builds lineage metadata
‚îÇ
‚îú‚îÄ‚îÄ debug_engine.py       ‚Üê Main engine - answers lineage questions
‚îú‚îÄ‚îÄ mcp_server.py         ‚Üê MCP server for AI agents
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Quick Start

### 1. Place Your Database

Put your `.duckdb` file anywhere. The engine auto-detects it from:
- `./data/*.duckdb`
- `./companies_data/*.duckdb`
- `./*.duckdb`
- Or set `DEBUG_AI_DB_PATH` environment variable

### 2. Test the Engine

```bash
python debug_engine.py
```

This will:
- Auto-detect your database
- List all schemas and tables
- Show sample lineage queries

### 3. (Optional) Build Metadata from SQL Files

If you have SQL transformation files:

```bash
python scripts/build_metadata.py --sql-dir /path/to/sql/files
```

### 4. Start MCP Server (for AI agents)

```bash
python mcp_server.py
```

---

## üîß Configuration Options

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DEBUG_AI_DB_PATH` | Path to database file | Auto-detected |
| `DEBUG_AI_ETL_DIR` | Path to SQL files | Auto-detected |
| `DEBUG_AI_DB_TYPE` | Database type | `duckdb` |

### Example: Custom Paths

```bash
export DEBUG_AI_DB_PATH=/data/warehouse.duckdb
export DEBUG_AI_ETL_DIR=/etl/transformations
python debug_engine.py
```

---

## üìñ Usage Examples

### Python API

```python
from debug_engine import DebugEngine

# Auto-detect database
engine = DebugEngine()

# Or specify path
engine = DebugEngine('/path/to/database.duckdb')

# Discovery
schemas = engine.list_schemas()
tables = engine.list_tables()
columns = engine.describe_table('raw.employees')

# Lineage
report = engine.trace_column_lineage('gold.report', 'total_sales')
sources = engine.get_upstream_tables('silver.fact_orders')
tree = engine.get_lineage_tree('gold.report')

# Debugging
health = engine.check_table_sources('silver.fact_orders')
row = engine.inspect_row('raw.customers', 'customer_id', 12345)
```

### MCP Tools (for AI Agents)

| Tool | Description |
|------|-------------|
| `list_schemas()` | Show available schemas |
| `list_tables(schema?)` | Show available tables |
| `describe_table(table)` | Show columns |
| `explain_column(table, column)` | **Main feature!** Show how column is calculated |
| `get_table_sources(table)` | Show upstream dependencies |
| `get_lineage_tree(table)` | Full dependency tree |
| `check_table_health(table)` | Debug data quality |
| `inspect_row(table, key_col, value)` | Look at specific data |
| `run_query(sql)` | Custom SQL (read-only) |

---

## üè¶ Client Examples

### Bank A
```python
engine = DebugEngine('/data/bank_warehouse.duckdb')
engine.trace_column_lineage('risk.customer_score', 'credit_rating')
```

### Hospital B  
```python
engine = DebugEngine('/data/hospital_data.duckdb')
engine.trace_column_lineage('analytics.patient_risk', 'readmission_probability')
```

### Retail C
```python
engine = DebugEngine('/data/retail.duckdb')
engine.trace_column_lineage('gold.sales_report', 'total_revenue')
```

**Same code, different databases!**

---

## üîí Security Features

- ‚úÖ SQL injection prevention (identifier validation)
- ‚úÖ Parameterized queries where possible
- ‚úÖ Read-only connections by default
- ‚úÖ Query keyword filtering (blocks DROP, DELETE, etc.)

---

## üîå Extending for New Databases

Add a new connector in `debug_engine.py`:

```python
class SnowflakeConnector(DatabaseConnector):
    def __init__(self, config: dict):
        # Initialize Snowflake connection
        pass
    
    def execute(self, query: str, params=None) -> pd.DataFrame:
        # Execute query
        pass
    
    def get_schemas(self) -> List[str]:
        # Return schemas
        pass
    
    def get_tables(self, schema=None) -> List[Dict]:
        # Return tables
        pass
```

Then update `DebugEngine.__init__()`:
```python
if db_type == 'snowflake':
    self.connector = SnowflakeConnector(config)
```

---

## üìù Metadata Schema

The engine expects these tables in a `meta` schema:

### `meta.table_lineage`
| Column | Type | Description |
|--------|------|-------------|
| target_table | VARCHAR | Table being created |
| source_table | VARCHAR | Table it reads from |
| sql_text | VARCHAR | Full SQL statement |

### `meta.column_lineage`
| Column | Type | Description |
|--------|------|-------------|
| target_table | VARCHAR | Table containing the column |
| target_column | VARCHAR | Column name |
| source_table | VARCHAR | Source table(s) |
| source_column | VARCHAR | Source column or 'COMPUTED' |
| transformation_logic | VARCHAR | SQL logic (CASE, AGG, etc.) |
| sql_file_name | VARCHAR | Source file name |

---

## ü§ù Contributing

1. Fork the repo
2. Add your database connector
3. Submit a PR

---

Built with ‚ù§Ô∏è for Data Engineers everywhere

**Created By: Omer Arbel**